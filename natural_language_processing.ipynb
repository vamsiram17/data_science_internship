{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-argentina",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "**Name : Vamsi Ram**\n",
    "\n",
    "**E-mail : vamsiramg@gmail.com**\n",
    "\n",
    "## What is Natural Language Processing?\n",
    "\n",
    "This Jupyter notebook includes the summary of my learnings from the resources provided in the Data Science Internship by wowlabz on conduira online platform.\n",
    "\n",
    "\n",
    "It can be defined as an artificial intelligence method of communicating with an intelligent system using natural language.\n",
    "It is a part of computer science and artificial intelligence which deals with human languages.\n",
    "\n",
    "This mainly involves two components,\n",
    "\n",
    "- Natural Language Understanding:\n",
    "Mapping the input to useful representations.\n",
    "Analyzing different aspects of the language.\n",
    "\n",
    "- Natural Language Generation:\n",
    "Producing meaningful phrases and sentences in the form of natural language.\n",
    "It involves text planning, sentence planning and text realization.\n",
    "\n",
    "\n",
    "Machine Learning with the text data involves,\n",
    "\n",
    "- Text Pre-processing – cleaning and formatting\n",
    "- Vectorization – converts text to numbers\n",
    "- Train the ML models using numerical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-switch",
   "metadata": {},
   "source": [
    "## Text Pre-processing:\n",
    "\n",
    "The process of making the data noise free and ready for analysis is called as text pre-processing. It involves three main steps,\n",
    "\n",
    "- Noise removal - stop words removal\n",
    "- Lexicon normalization – stemming and lemmatization\n",
    "- Object standardization – by standardizing the words or phrases which are not present in the standard dictionaries.\n",
    "\n",
    "\n",
    "## Text to features\n",
    "\n",
    "This can be defined as the feature engineering on the text data. Depending upon the usage and occurrence of the words, text features are constructed.\n",
    "\n",
    "**Syntactic Parsing**:\n",
    "\n",
    "- The analysis of the words in a sentence for grammar and they are arranged in an order such that there is relationship among the words.\n",
    "- This can be done with the techniques such as Dependency trees and Part of speech tagging.\n",
    "- The dependency trees depict the relationship among the words in the  form of a tree where a root word is connected to different sub words.\n",
    "- The parts of speech tags define the usage and function of a word in a sentence.\n",
    "\n",
    "The above mentioned methods can be used in various application such as improving word based features, normalization and lemmatization and efficient stop word removal.\n",
    "\n",
    "## Entity Extraction\n",
    "\n",
    "The most important parts of a sentence wither be the nouns, verbs or both are defined as entities. These entity detection algorithms are ensemble models of parsing and tagging.\n",
    "\n",
    "This can be done be done with techniques such as \n",
    "\n",
    "- Name Entity Recognition: which is generally the process of detecting the important names from the text.\n",
    "\n",
    "- Topic Modelling: which is the process of identifying the topics present in the text and to derive hidden patterns among the words. **Latent Dirichlet Allocation** is the popular topic modelling technique.\n",
    "\n",
    "A combination of N words together would provide us with more information than a single word. So entities are created and defined as N-Grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-sandwich",
   "metadata": {},
   "source": [
    "## Tokenization:\n",
    "\n",
    "This is process of breaking a complex sentence into words and called as tokens.\n",
    "We need to understand the importance of each of the words with respect to sentence and produce a structural description of an input sequence.\n",
    "\n",
    "- Stop Words removal:\n",
    "This involves removal of the words that frequently appear in texts and don’t contribute too much to the overall meaning.\n",
    "\n",
    "- Bag of Words(BoW) method:\n",
    "It converts text data into numerical features.\n",
    "This can be considered as feature extraction, as we extract the important information from the text and convert it into numeric form.\n",
    "For each word in the text, we get either binary 0 or 1 or it can be the count or frequency of the particular words. \n",
    "\n",
    "- Term Frequency(TF):\n",
    "It increase the weight of the common words in a document.\n",
    "\n",
    "- Inverse Document Frequnecy(IDF):\n",
    "It decreases the weight for commonly used words and increases the weight for the rare words in the vocabulary.\n",
    "\n",
    "- N-gram:\n",
    "An n gram is a sequence of n tokens from a given sample of text. These can be used to represent larger words as a single token.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-congress",
   "metadata": {},
   "source": [
    "## Word Embedding:\n",
    "\n",
    "It is a way of representing words as vectors. It’s main purpose is to redefine the high dimensional word features as a low dimensional entities. Also the context is preserved in the corpus.\n",
    "\n",
    "- Word2Vec:\n",
    "It contains two shallow neural network components which are, Continuous Bag of Words and Skip-Gram. Initially it constructs a vocabulary from the training corpus and learns the word embedding relations.\n",
    "\n",
    "\n",
    "## Applications of NLP:\n",
    "\n",
    "- Text Summarization\n",
    "- Machine Translation\n",
    "- Optical Character Recognition\n",
    "- Text Classification\n",
    "- Text Matching\n",
    "- Coreference Resolution\n",
    "- Speech to text and text to speech conversion\n",
    "- Topic discovery and modelling\n",
    "- Sentiment analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-metro",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Hence in this notebook I have briefly explained what is Natural Language Processing and the basic methods in which it is  made use for various applications.\n",
    "I am greatly obliged and thank wowlabz for providing me the valuable learning resources in this internship.I also take this oppurtunity to thank Conduira online for providing me a platform in order to learn and develop my skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
